{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2bbfe56c-79ed-450e-81fd-64789ea58ba8",
   "metadata": {},
   "source": [
    "# Clasificación - modelos supervisados a partir de la matriz F2V\n",
    "\n",
    "Este Notebook entrena modelos de clasificación para predecir si una película es de inmigración o no a partir de la matriz $F2V$, y toma las probabilidades predichas por el mejor modelo como índice de contenido de inmigración de cada película.\n",
    "\n",
    "1. [Calcular F2V](#f2v)\n",
    "2. [Modelos de clasificación](#clasif)\n",
    "3. [Probabilidades predichas como índice de inmigración](#proba)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "650aa7bc-258f-4991-aa0c-43bc7abc352d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importamos librerías \n",
    "\n",
    "## Módulos generales\n",
    "from libraries import *\n",
    "\n",
    "## Módulos con funciones creadas para este trabajo\n",
    "## (requieren de haber importado previamente los módulos generales)\n",
    "from limpieza_subt import *\n",
    "from clustering import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f0cda3-1e5a-4ca0-97d5-85eace2adccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Completar con directorios \n",
    "gitwd = \"\"\n",
    "datawd = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad370c17-18b9-4373-a45a-cc5cc8348c16",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Importar datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e341ab7c-714b-4816-a608-cc172b89f3ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "l2v = pd.read_pickle(datawd + \"/l2v.pkl\")\n",
    "\n",
    "with open(datawd + \"/tfidf.pkl\", 'rb') as inputfile: \n",
    "    tfidf = pickle.load(inputfile)\n",
    "      \n",
    "filmids = pd.read_pickle(datawd + \"/filmids.pkl\")\n",
    "master = pd.read_csv(datawd + \"/titles_master.csv\")\n",
    "\n",
    "with open(datawd + \"/stoi.pkl\", 'rb') as inputfile: \n",
    "    stoi = pickle.load(inputfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "024e1cc1-d90d-4bdb-8cf8-c25139b2f75c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Algo de limpieza\n",
    "l2v =l2v.sort_values(\"stoi\").reset_index(drop = True) # ordenar valores L2V por STOI\n",
    "tfidf = tfidf.toarray()\n",
    "\n",
    "filmids = filmids[[\"tconst\", \"filmid\"]].merge(master,\n",
    "                                   on = \"tconst\",\n",
    "                                   how = \"left\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55232ac8-5e87-469f-af2b-89808eabfdbc",
   "metadata": {
    "tags": []
   },
   "source": [
    "<a id='f2v'></a>\n",
    "\n",
    "## F2V: matriz de variables explicativas\n",
    "La matriz de features F2V (película-a-vector) se calcula como TFIDF x L2V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2695ad38-12d8-41b0-a959-d757af67ce53",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = tfidf[:,2:] # quitar columnas correspondientes a PAD y UNK\n",
    "print(tfidf.shape) \n",
    "print(l2v.iloc[:,2:-1].shape) # quitar columnas que no son dimensiones\n",
    "\n",
    "# films to vec!\n",
    "f2v = tfidf.dot(l2v.iloc[:,2:-1]) \n",
    "f2v = pd.DataFrame(f2v)\n",
    "f2v.columns = [\"dim_\" + str(x) for x in f2v.columns]\n",
    "f2v = pd.concat([filmids, f2v], axis = 1) # agregamos los ids y otros datos de las películas, como la respuesta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9065f8bf-edbe-46c8-94e9-2251e94cb808",
   "metadata": {
    "tags": []
   },
   "source": [
    "Quitamos películas extra-inimigración para este análisis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d927076d-60b4-4e63-b939-8f062646982f",
   "metadata": {},
   "outputs": [],
   "source": [
    "f2v = f2v[(f2v.main == 1) | (f2v.before2000 == 1)].reset_index(drop = True)\n",
    "f2v.shape\n",
    "\n",
    "f2v.to_pickle(datawd + \"/tfidf2vec.pkl\")\n",
    "f2v[[\"tconst\", \"just_migra\"]].to_csv(datawd + \"/target.csv\", index = False) # también guardamos la variable de respuesta por separado"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25032bea-554d-447f-b802-d562ee53b8b4",
   "metadata": {
    "tags": []
   },
   "source": [
    "<a id='clasif'></a>\n",
    "\n",
    "## Modelos de clasificación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d91ee07-e7df-41f6-b460-afe90f94969f",
   "metadata": {},
   "outputs": [],
   "source": [
    "f2v = pd.read_pickle(datawd + f\"/tfidf2vec.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8af1ef9e-2b58-463e-a960-d351270e2273",
   "metadata": {
    "tags": []
   },
   "source": [
    "###  X e y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e48cf4bf-c260-4229-bee1-1b095988ffd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X son siempre los vectores\n",
    "dims = [x for x in f2v.columns if \"dim_\" in x]\n",
    "X =  f2v[dims]\n",
    "\n",
    "# y es la variable de respuesta: si una película es de inmigración o no (variable just_migra)\n",
    "y = f2v.loc[:,\"just_migra\"]\n",
    "print(np.mean(y)) # Mucho debalance!!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9858e7a8-57b3-4ec1-b1c7-ca0f79045374",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Multicolinealidad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49f7039f-f827-4577-b3ae-d2dcc9e923fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "multic = abs(X.corr(method='pearson'))\n",
    "\n",
    "result_df2 =(multic>0.5)  & (multic < 1)  \n",
    "result_df2 = np.sum(result_df2, axis = 0)  \n",
    "\n",
    "print(np.sum(result_df2 > 0)) \n",
    "print(np.sum(result_df2 > np.percentile(result_df2, 95))) \n",
    "\n",
    "# Quitar dimensiones con alta multicolinealidad\n",
    "okvars = result_df2.index[result_df2 < np.percentile(result_df2, 95)]\n",
    "print(len(okvars))\n",
    "X_corrected = X[okvars]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91de0047-7c99-4dc7-9fa3-65d5c8f43ca9",
   "metadata": {},
   "source": [
    "### Split train - test y SMOTE para sobremuestrar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47913752-ed63-44bb-9254-06275d5ff3f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Hacemos el split train-test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_corrected,y,test_size = 0.25, random_state = 42)\n",
    "\n",
    "sm = SMOTE(random_state=42)\n",
    "X_res, y_res = sm.fit_resample(X_train, y_train)\n",
    "\n",
    "print(np.mean(y_train),\n",
    "      np.mean(y_res))\n",
    "\n",
    "## Creamos una lista donde vamos a guardar todos los hiperparámetros ajustados\n",
    "hyperparameters = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a87a963a-3490-4584-b45f-51a1b0f8c79a",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Comparar con y sin SMOTE para logit-lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc61b939-72e5-4251-aabd-b32a55d78159",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression()\n",
    "parameters = {'penalty': ['l1', 'l2', 'none'],\n",
    "              'solver': ['saga'],\n",
    "               'C' : [0.5, 1, 5],\n",
    "               'max_iter': [20000]}\n",
    "\n",
    "# con  SMOTE\n",
    "grid_obj = GridSearchCV(lr, parameters, scoring='roc_auc', cv=3)\n",
    "grid_fit = grid_obj.fit(X_res,y_res)\n",
    "lr_best_params = grid_obj.best_params_\n",
    "lr = LogisticRegression(**lr_best_params)\n",
    "lr = lr.fit(X_res, y_res)\n",
    "y_train_pred_lr = lr.predict(X_train)\n",
    "y_test_pred_lr = lr.predict(X_test)\n",
    "y_res_pred_lr = lr.predict(X_res)\n",
    "\n",
    "print(lr_best_params)\n",
    "print(np.mean(y_test_pred_lr))\n",
    "\n",
    "print(balanced_accuracy_score(y_test, y_test_pred_lr),\n",
    "      roc_auc_score(y_test, y_test_pred_lr),\n",
    "      accuracy_score(y_test, y_test_pred_lr))\n",
    "\n",
    "# sin SMOTE\n",
    "grid_obj2 = GridSearchCV(lr, parameters, scoring='roc_auc', cv=3)\n",
    "grid_fit2 = grid_obj2.fit(X_train,y_train)\n",
    "lr_best_params2 = grid_obj2.best_params_\n",
    "lr = LogisticRegression(**lr_best_params2)\n",
    "lr = lr.fit(X_train, y_train)\n",
    "y_train_pred_lr = lr.predict(X_train)\n",
    "y_test_pred_lr = lr.predict(X_test)\n",
    "\n",
    "print(lr_best_params2)\n",
    "print(np.mean(y_test_pred_lr))\n",
    "\n",
    "print(balanced_accuracy_score(y_test, y_test_pred_lr),\n",
    "      roc_auc_score(y_test, y_test_pred_lr),\n",
    "      accuracy_score(y_test, y_test_pred_lr))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67333348-d8bd-4fb2-a625-b3f152a2be9e",
   "metadata": {},
   "source": [
    "### Entrenar varios modelos con SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a03498-220c-445a-9df5-737291a61385",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive Bayes\n",
    "start_time = time.time()\n",
    "gnb = GaussianNB()\n",
    "gnb = gnb.fit(X_res, y_res)\n",
    "a = time.time()\n",
    "print(\"Naive Bayes:\" , (a - start_time)/ 60)\n",
    "\n",
    "# Logit-Lasso\n",
    "lr = LogisticRegression()\n",
    "parameters = {'penalty': ['l1', 'l2', 'none'],\n",
    "              'solver': ['saga'],\n",
    "              'max_iter': [20000]}\n",
    "grid_obj = GridSearchCV(lr, parameters, scoring='roc_auc', cv=3)\n",
    "grid_fit = grid_obj.fit(X_res,y_res)\n",
    "lr_best_params = grid_obj.best_params_\n",
    "hyperparameters['LogisticRegression'] = lr_best_params\n",
    "lr = LogisticRegression(**lr_best_params)\n",
    "lr = lr.fit(X_res, y_res)\n",
    "b = time.time()\n",
    "print(\"Logit:\", (b-a)/ 60)\n",
    "\n",
    "# Random Forest Classifier\n",
    "rfclass = RandomForestClassifier(random_state=42)\n",
    "parameters = {'n_estimators': [100, 200],\n",
    "              'max_depth' : [5,10],\n",
    "              'criterion' :['gini', 'entropy'],\n",
    "              'min_impurity_decrease': [0.001,0.1]}\n",
    "grid_obj = GridSearchCV(rfclass, parameters, scoring='roc_auc', cv=3)\n",
    "grid_fit = grid_obj.fit(X_res, y_res)\n",
    "rfclass_best_params = grid_obj.best_params_\n",
    "hyperparameters['RandomForest'] = rfclass_best_params\n",
    "rfclass = RandomForestClassifier(**rfclass_best_params, random_state=42)\n",
    "rfclass = rfclass.fit(X_res,y_res)\n",
    "c = time.time()\n",
    "print(\"Random Forest:\", (c-b)/ 60)\n",
    "\n",
    "#### Linear Discriminant Analysis\n",
    "ldaclass = LinearDiscriminantAnalysis()\n",
    "parameters = {'tol' : [0.0001,0.0003]}\n",
    "grid_obj = GridSearchCV(ldaclass, parameters, scoring='roc_auc',cv=3)\n",
    "grid_fit = grid_obj.fit(X_res, y_res)\n",
    "lda_best_params = grid_obj.best_params_\n",
    "hyperparameters['LinearDiscriminantAnalysis'] = lda_best_params\n",
    "ldaclass = LinearDiscriminantAnalysis(**lda_best_params)\n",
    "ldaclass = ldaclass.fit(X_res, y_res)\n",
    "d = time.time()\n",
    "print(\"LDA:\", (d-c)/ 60)\n",
    "\n",
    "\n",
    "### Quadratic Discriminant Analysis\n",
    "# a. Tuneamos los hiperparámetros por CV\n",
    "qdaclass = QuadraticDiscriminantAnalysis()\n",
    "parameters = {'reg_param': [0.05, 0.15 ,0.3, 0.5]}\n",
    "grid_obj = GridSearchCV(qdaclass, parameters, scoring='roc_auc',cv=3)\n",
    "grid_fit = grid_obj.fit(X_res, y_res)\n",
    "qda_best_params = grid_obj.best_params_\n",
    "hyperparameters['QuadraticDiscriminantAnalysis'] = qda_best_params\n",
    "# b. Ajustamos el modelo y predecimos\n",
    "qdaclass = QuadraticDiscriminantAnalysis(**qda_best_params)\n",
    "qdaclass = qdaclass.fit(X_res, y_res)\n",
    "e = time.time()\n",
    "print(\"QDA:\", (e-d)/ 60)\n",
    "\n",
    "# 6. K Nearest Neighbors\n",
    "# a. Tuneamos los hiperparámetros por CV\n",
    "knnclass = KNeighborsClassifier()\n",
    "parameters = {'n_neighbors':[1,5,9,21],\n",
    "              'weights': ['uniform','distance'],\n",
    "              'metric': ['euclidean','cosine']}\n",
    "grid_obj = GridSearchCV(knnclass, parameters, scoring='roc_auc', cv=3)\n",
    "grid_fit = grid_obj.fit(X_res, y_res)\n",
    "knnclass_best_params = grid_obj.best_params_\n",
    "hyperparameters['KNeighbors'] = knnclass_best_params\n",
    "# b. Ajustamos el modelo y predecimos\n",
    "knnclass = KNeighborsClassifier(**knnclass_best_params)\n",
    "knnclass = knnclass.fit(X_res,y_res)\n",
    "f = time.time()\n",
    "print(\"KNN\", (f-e)/ 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceb156c9-8f9e-4602-ba29-8a68b803706e",
   "metadata": {},
   "source": [
    "### Predicciones y métricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5952ff9a-18b9-47f1-8679-e3292bfe95cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicciones train y test para las métricas (sobre X SIN SMOTE)\n",
    "y_train_pred_gbn = gnb.predict(X_train)\n",
    "y_test_pred_gbn = gnb.predict(X_test)\n",
    "\n",
    "y_train_pred_lr = lr.predict(X_train)\n",
    "y_test_pred_lr = lr.predict(X_test)\n",
    "\n",
    "y_train_pred_rfclass = rfclass.predict(X_train)\n",
    "y_test_pred_rfclass = rfclass.predict(X_test)\n",
    "\n",
    "y_train_pred_ldaclass = ldaclass.predict(X_train)\n",
    "y_test_pred_ldaclass = ldaclass.predict(X_test)\n",
    "\n",
    "y_train_pred_qdaclass = qdaclass.predict(X_train)\n",
    "y_test_pred_qdaclass = qdaclass.predict(X_test)\n",
    "\n",
    "y_train_pred_knnclass = knnclass.predict(X_train)\n",
    "y_test_pred_knnclass = knnclass.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2fa0f02-8345-41bd-9135-13271e02dfc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar métricas e hiperparámetros\n",
    "test_metrics = pd.DataFrame({'Algorithms':['Gaussian Naive Bayes',\n",
    "                                         'Linear Discriminant Analysis',\n",
    "                                         'Quadratic Discriminant Analysis',\n",
    "                                         'Logistic Regression',\n",
    "                                         'Random Forest Classifier',\n",
    "                                         'K Nearest Neighbors'],\n",
    "                             'ROC-scores':[roc_auc_score(y_test,y_test_pred_gbn),\n",
    "                                           roc_auc_score(y_test,y_test_pred_ldaclass),\n",
    "                                           roc_auc_score(y_test,y_test_pred_qdaclass),\n",
    "                                           roc_auc_score(y_test,y_test_pred_lr),\n",
    "                                           roc_auc_score(y_test,y_test_pred_rfclass),\n",
    "                                           roc_auc_score(y_test,y_test_pred_knnclass)],\n",
    "                           'Balanced_acc-scores':[   balanced_accuracy_score(y_test,y_test_pred_gbn),\n",
    "                                                      balanced_accuracy_score(y_test,y_test_pred_ldaclass),\n",
    "                                                      balanced_accuracy_score(y_test,y_test_pred_qdaclass),\n",
    "                                                      balanced_accuracy_score(y_test,y_test_pred_lr),\n",
    "                                                      balanced_accuracy_score(y_test,y_test_pred_rfclass),\n",
    "                                                      balanced_accuracy_score(y_test,y_test_pred_knnclass)],\n",
    "                                    'Acc-scores':[    accuracy_score(y_test,y_test_pred_gbn),\n",
    "                                                      accuracy_score(y_test,y_test_pred_ldaclass),\n",
    "                                                      accuracy_score(y_test,y_test_pred_qdaclass),\n",
    "                                                      accuracy_score(y_test,y_test_pred_lr),\n",
    "                                                      accuracy_score(y_test,y_test_pred_rfclass),\n",
    "                                                      accuracy_score(y_test,y_test_pred_knnclass)]\n",
    "                         })\n",
    "\n",
    "train_metrics = pd.DataFrame({'Algorithms':['Gaussian Naive Bayes',\n",
    "                                         'Linear Discriminant Analysis',\n",
    "                                         'Quadratic Discriminant Analysis',\n",
    "                                         'Logistic Regression',\n",
    "                                         'Random Forest Classifier',\n",
    "                                         'K Nearest Neighbors'],\n",
    "                             'ROC-scores':[roc_auc_score(y_train,y_train_pred_gbn),\n",
    "                                           roc_auc_score(y_train,y_train_pred_ldaclass),\n",
    "                                           roc_auc_score(y_train,y_train_pred_qdaclass),\n",
    "                                         roc_auc_score(y_train,y_train_pred_lr),\n",
    "                                         roc_auc_score(y_train,y_train_pred_rfclass),\n",
    "                                         roc_auc_score(y_train,y_train_pred_knnclass)],\n",
    "                           'Balanced_acc-scores':[  balanced_accuracy_score(y_train,y_train_pred_gbn),\n",
    "                                                      balanced_accuracy_score(y_train,y_train_pred_ldaclass),\n",
    "                                                      balanced_accuracy_score(y_train,y_train_pred_qdaclass),\n",
    "                                                      balanced_accuracy_score(y_train,y_train_pred_lr),\n",
    "                                                      balanced_accuracy_score(y_train,y_train_pred_rfclass),\n",
    "                                                      balanced_accuracy_score(y_train,y_train_pred_knnclass)],\n",
    "                                    'Acc-scores':[    accuracy_score(y_train,y_train_pred_gbn),\n",
    "                                                      accuracy_score(y_train,y_train_pred_ldaclass),\n",
    "                                                      accuracy_score(y_train,y_train_pred_qdaclass),\n",
    "                                                      accuracy_score(y_train,y_train_pred_lr),\n",
    "                                                      accuracy_score(y_train,y_train_pred_rfclass),\n",
    "                                                      accuracy_score(y_train,y_train_pred_knnclass)]\n",
    "                         })\n",
    "\n",
    "train_metrics.to_pickle(datawd + f\"/clasif_train_metrics.pkl\")\n",
    "test_metrics.to_pickle(datawd + f\"/clasif_test_metrics.pkl\")\n",
    "with open(datawd + f\"/clasif_hyperparameters.pkl\", 'wb') as outputfile: \n",
    "    pickle.dump(hyperparameters, outputfile)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7542639a-f5dc-4f7f-8b2b-887cef52092f",
   "metadata": {},
   "source": [
    "### Visualizar métricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69545557-9b11-4a94-a9c7-8987d88d0773",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_metrics = pd.read_pickle(datawd + f\"/clasif_train_metrics.pkl\")\n",
    "test_metrics = pd.read_pickle(datawd + f\"/clasif_test_metrics.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bbdae46-989e-48f3-a7df-3e2c311a9e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train\n",
    "fig, ax = plt.subplots(figsize=(6, 4))\n",
    "ax = sns.heatmap(train_metrics[['ROC-scores', 'Acc-scores', 'Balanced_acc-scores']], \n",
    "                 yticklabels=train_metrics.Algorithms , \n",
    "                 annot=True ,\n",
    "                 cmap = sns.cm.rocket_r)\n",
    "ax = plt.xticks(rotation=0)\n",
    "ax = plt.title('Train metrics', fontsize=14)\n",
    "plt.savefig(datawd + f\"/metrics_clasif_TRAIN.png\", dpi = 300, bbox_inches='tight')\n",
    "ax = plt.show()\n",
    "\n",
    "# test\n",
    "fig, ax = plt.subplots(figsize=(6, 4))\n",
    "ax = sns.heatmap(test_metrics[['ROC-scores', 'Acc-scores', 'Balanced_acc-scores']], \n",
    "                 yticklabels=test_metrics.Algorithms , \n",
    "                 annot=True ,\n",
    "                 cmap = sns.cm.rocket_r)\n",
    "ax = plt.xticks(rotation=0)\n",
    "ax = plt.title('Test metrics', fontsize=14)\n",
    "plt.savefig(datawd + f\"/metrics_clasif_TEST.png\", dpi = 300, bbox_inches='tight')\n",
    "ax = plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "433dda0f-d875-465e-a11d-51e479b28eae",
   "metadata": {},
   "source": [
    "<a id='proba'></a>\n",
    "\n",
    "## Probabilidades predichas como índice de inmigración"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f7a9844-0038-4d7d-a63b-97d80d6de6a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tomamos la regresión logística, uno de los mejores modelos, y predecimos las probabilidades sobre todo el conjunto de películas\n",
    "with open(datawd + f\"/clasif_hyperparameters.pkl\", 'rb') as outputfile: \n",
    "    hyperparameters = pickle.load(outputfile)\n",
    "lr = LogisticRegression(**hyperparameters['LogisticRegression'])\n",
    "lr = lr.fit(X_res, y_res)\n",
    "\n",
    "# Predicciones de probabilidad para el score tomando el mejor modelos\n",
    "y_pred_proba = lr.predict_proba(X_corrected)\n",
    "\n",
    "immi_proba = f2v[[\"tconst\", \"just_migra\"]]\n",
    "immi_proba[\"lr_pred_proba\"] = y_pred_proba[:,1]\n",
    "immi_proba[\"lr_pred\"] = lr.predict(X_corrected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ad7a36-3e88-4d88-9172-d261f5b0aa4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matriz de confusión\n",
    "disp = plot_confusion_matrix(lr, X_test, y_test, normalize='true',cmap='binary')\n",
    "disp.ax_.set_title(\"Regresión Logística - matriz de confusión - TEST\")\n",
    "disp.im_.colorbar.remove()\n",
    "\n",
    "plt.savefig(datawd + f\"/conf_matrix_lr.png\", dpi = 300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02b3af7e-7a95-4543-a56c-223b01e2089c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Curva ROC usando probabilidades\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_test,  lr.predict_proba(X_test)[:,1], drop_intermediate =True)\n",
    "i = 100\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "display = metrics.RocCurveDisplay(fpr=fpr, tpr=tpr, roc_auc=roc_auc,\n",
    "                                  estimator_name='Regresión Logística')\n",
    "display.plot()\n",
    "plt.plot([0, 1], [0, 1], color='black', linestyle='--')\n",
    "plt.scatter(fpr[i], tpr[i], label = f\"Umbral = {round(thresholds[ i ], 3)}\", color = \"red\")\n",
    "plt.title('Regresión logística - curva ROC - TEST')\n",
    "plt.legend()\n",
    "plt.savefig(datawd + f\"/curva_roc_lr.png\", dpi = 300, bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef1ba44e-f3ff-4815-894e-df4dac0e8e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Curva ROC usando predicción binaria\n",
    "\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_test,  lr.predict(X_test), drop_intermediate =True)\n",
    "\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "display = metrics.RocCurveDisplay(fpr=fpr, tpr=tpr, roc_auc=roc_auc,\n",
    "                                  estimator_name='Regresión Logística')\n",
    "display.plot()\n",
    "plt.plot([0, 1], [0, 1], color='black', linestyle='--')\n",
    "\n",
    "plt.title('Curva ROC en datos de Test - Regresión logística')\n",
    "plt.legend()\n",
    "plt.savefig(datawd + f\"/curva_roc_lr_b.png\", dpi = 300, bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "776e5ebc-d69b-492e-9a7f-2023f151a258",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Probabilidad promedio y porcentaje predicho como de inmigración según etiqueta real\n",
    "immi_proba.groupby(\"just_migra\")[[\"lr_pred_proba\",\"lr_pred\"]].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "941adb57-a686-4209-b2d1-807cc0ee3d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Box-Plot según etiqueta real\n",
    "plt.figure(figsize=(8, 6))  \n",
    "sns.boxplot(x='just_migra', y='lr_pred_proba', data=immi_proba, palette='viridis')\n",
    "plt.axhline(y=0.5, color='red', linestyle='--', linewidth=2)\n",
    "plt.xlabel('Etiqueta de inmigración según IMDb')\n",
    "plt.ylabel('Probabilidad Regresión Logística')\n",
    "plt.title('Boxplots de probabilidad predicha según etiqueta real')\n",
    "plt.savefig(datawd + f\"/boxplot_lr.png\", dpi = 300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee0b697e-92d4-4bbd-8570-8f7c5c68a452",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogramas de probabilidad predicha según etiqueta real\n",
    "plt.figure(figsize=(8, 6), dpi=80)\n",
    "plt.hist(immi_proba[immi_proba.just_migra == 0].lr_pred_proba, bins = 20, alpha=0.5, label='Películas No Inmigración', density =True)\n",
    "plt.hist(immi_proba[immi_proba.just_migra == 1].lr_pred_proba, bins = 20, alpha=0.5, label='Películas Inmigración', density = True)\n",
    "plt.legend(loc='upper right')\n",
    "\n",
    "plt.savefig(datawd + f\"/hist_lr.png\", dpi = 300)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
