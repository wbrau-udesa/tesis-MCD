{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7190468b-22e2-4284-a6ac-ce82b35eb24f",
   "metadata": {},
   "source": [
    "# CLUSTERING - valores de cada película en cada clúster \n",
    "\n",
    "Este Notebook asigna un valor a cada película en cada clúster/temática de inmigración (matriz $F2C$), y entrena modelos de regresión para predecir el valor de una película en un clúster. Pasos:\n",
    "\n",
    "1. [Matriz $F2C$](#f2c)\n",
    "2. [Modelos de regresión](#modelos)\n",
    "\n",
    "\n",
    "Inputs:\n",
    "- Matriz $L2V$, matriz $TFIDF$, clústers finales\n",
    "\n",
    "Outputs:\n",
    "- Matriz $F2C$\n",
    "- Modelos de regresión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "217b0aab-8928-4048-8ec5-5479497b1b85",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Importamos librerías \n",
    "\n",
    "## Módulos generales\n",
    "from libraries import *\n",
    "\n",
    "## Módulos con funciones creadas para este trabajo\n",
    "## (requieren de haber importado previamente los módulos generales)\n",
    "from limpieza_subt import *\n",
    "from clustering import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d1ce4e7-a85d-4e82-b682-50174f2b868c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Completar con directorios \n",
    "gitwd = \"\"\n",
    "datawd = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad370c17-18b9-4373-a45a-cc5cc8348c16",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Importar datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "708297e3-ba75-4801-9c73-fc7c1f054b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "l2v = pd.read_pickle(datawd + \"/l2v.pkl\")\n",
    "\n",
    "with open(datawd + \"/tfidf.pkl\", 'rb') as inputfile: \n",
    "    tfidf = pickle.load(inputfile)\n",
    "\n",
    "filmids = pd.read_pickle(datawd + \"/filmids.pkl\")\n",
    "\n",
    "with open(datawd + \"/stoi.pkl\", 'rb') as inputfile: \n",
    "    stoi = pickle.load(inputfile)\n",
    "    \n",
    "l2v = l2v.sort_values(\"stoi\").reset_index(drop = True) # Ordenar lemas de L2V según STOI\n",
    "tfidf = tfidf.toarray()\n",
    "\n",
    "master = pd.read_csv(datawd + \"/titles_master.csv\")\n",
    "msubt = filmids[[\"tconst\", \"filmid\"]].merge(master,\n",
    "                                   on = \"tconst\",\n",
    "                                   how = \"left\")\n",
    "\n",
    "del master\n",
    "\n",
    "master = pd.read_pickle(datawd + \"/master_subt_content_cleaned.pkl\")  \n",
    "master = master[[\"tconst\", \"n_tokens\"]]\n",
    "msubt = msubt.merge(master,\n",
    "                    on = \"tconst\",\n",
    "                    how = \"left\")\n",
    "\n",
    "del master\n",
    "\n",
    "msubt = msubt[[\"tconst\", \"filmid\", \"just_migra\"]]\n",
    "\n",
    "msubt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "112a9cb0-aa7d-450d-b30e-eadeadfad1ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = pd.read_pickle(datawd + f\"/clusters500/final_clusters500.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f6b1331-b1f9-47ff-89a6-1f0c1a8bcc13",
   "metadata": {
    "tags": []
   },
   "source": [
    "<a id='f2c'></a>\n",
    "## Matriz F2C\n",
    "\n",
    "Para obtener la matriz película-a-clúster (F2C), multiplicamos dos matrices:\n",
    "\n",
    "1) tfidf_clusters (F películas x L lemas en los clústers): valor TFIDF para los lemas presentes en los clústers de inmigración\n",
    "2) clusters_matrix (L lemas en los clústers x C clústers): matrix con lemas en las filas y clústers en la columna, y un 1 indicando que cierto lema pertenece a cierto clúster\n",
    "\n",
    "F2C = tfidf_clusters . clusters_matrix (F x C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b14fb8f-4433-4f0b-8555-6e93ccc5c63b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tfidf_clusters\n",
    "relevant_words = np.unique([item for sublist in clusters.lemmas for item in sublist])\n",
    "relevant_words = { k:v for k, v in stoi.items() if k in relevant_words}\n",
    "print(\"Número de lemas únicos en los clusters:\" ,len(relevant_words ))\n",
    "relevant_words_index = sorted([x for x in relevant_words.values()])\n",
    "stoi_to_index = dict(zip(relevant_words_index , np.arange(0,len(relevant_words))))\n",
    "tfidf_clusters = tfidf[:,relevant_words_index] # (F x L) con lemas ordenados por stoi \n",
    "print(tfidf_clusters.shape)\n",
    "\n",
    "# clusters_matrix\n",
    "aux = clusters.explode(\"lemmas\")\n",
    "print(aux.shape)\n",
    "aux[\"aux\"] = 1\n",
    "aux[\"stoi\"] = aux[\"lemmas\"].map(relevant_words) # agregar STOI para poder combinar con tfidf_clusters\n",
    "aux = aux.sort_values(\"stoi\").reset_index(drop = True)  \n",
    "aux[\"new_index\"] = aux.stoi.map(stoi_to_index)\n",
    "clusters_matrix = sp.coo_matrix( ( aux['aux'], (aux[\"new_index\"], aux['f_cluster_id'])) )\n",
    "clusters_matrix = clusters_matrix.toarray()\n",
    "print(clusters_matrix.shape )\n",
    "\n",
    "# F2C\n",
    "f2c = np.matmul(tfidf_clusters, clusters_matrix)\n",
    "print(f2c.shape)\n",
    "f2c = pd.DataFrame(f2c)\n",
    "f2c.columns =  clusters[\"manual_grouping_name\"] # películas ya ordenadas por índices\n",
    "f2c = pd.concat([filmids, f2c], axis = 1)\n",
    "\n",
    "f2c[\"clusters_sum\"] = f2c.loc[:,clusters[\"manual_grouping_name\"]].sum(axis = 1)\n",
    "\n",
    "f2c.to_pickle(datawd + f\"/clusters{k}/f2c.pkl\")\n",
    "f2c.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1feae573-794a-4fda-9568-af4076e12585",
   "metadata": {
    "tags": []
   },
   "source": [
    "<a id='modelos'></a>\n",
    "## Modelos de regresión"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55232ac8-5e87-469f-af2b-89808eabfdbc",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Matriz X\n",
    "Como matriz de features se promedian los embeddings de todos los lemas de la película"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b146aef-6588-4375-ad1b-c7626a6d2cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformar TFIDF a matriz binaria: si una palabra aparece en una peli o no\n",
    "has_words = tfidf[:,2:] #  quitar columnas de PAD y UNK\n",
    "has_words[has_words > 0] = 1\n",
    "del tfidf\n",
    "print(has_words.shape)\n",
    "print(l2v.iloc[:,2:-1].shape) # quitando columnas que no son dimensiones del vector de embeddings\n",
    "\n",
    "# film to vec!\n",
    "f2v = has_words.dot(l2v.iloc[:,2:-1]) # Suma las dimensiones de todos los lemas de la película\n",
    "print(f2v.shape)\n",
    "tot_words = np.sum(has_words, axis = 1) # total de lemas por película\n",
    "f2v = f2v/ (tot_words[:, np.newaxis]) # dividir por el total de lemas por película (para obtener el promedio)\n",
    "\n",
    "# pasar a DataFrame y agregar los identificadores de las películas\n",
    "f2v = pd.DataFrame(f2v)\n",
    "f2v.columns = [\"dim_\" + str(x) for x in f2v.columns]\n",
    "f2v = pd.concat([filmids, f2v], axis = 1)\n",
    "f2v.to_pickle(datawd + \"/X_regre.pkl\")\n",
    "del f2v\n",
    "\n",
    "dims = [x for x in f2v.columns if \"dim_\" in x]\n",
    "X =  f2v[dims] # X es el vector promedio de embeddings para cada película\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b83a0b58-edeb-4b6e-af11-db502728ccef",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Corregir multicolinealidad\n",
    "Para obtener X_corrected, la matriz de features a usar en los modelos de regresión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e95a9db-a74e-4770-937b-02138d78aed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dims = [x for x in f2v.columns if \"dim_\" in x]\n",
    "X =  f2v[dims] # X es el vector promedio de embeddings para cada película\n",
    "multic = abs(X.corr(method='pearson'))\n",
    "\n",
    "result_df2 =(multic>0.5)  & (multic < 1)  \n",
    "result_df2 = np.sum(result_df2, axis = 0)  # número de dimensiones con las que correlaciona\n",
    "\n",
    "print(np.sum(result_df2 > 0)) \n",
    "print(np.sum(result_df2 >= np.percentile(result_df2, 95)))\n",
    "\n",
    "# Quitar variables con alta multicolinealidad\n",
    "okvars = result_df2.index[result_df2 < np.percentile(result_df2, 95)]\n",
    "print(len(okvars))\n",
    "X_corrected = X[okvars]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b92faf24-655d-4f16-9e5b-5e68b530d650",
   "metadata": {},
   "source": [
    "### Entrenar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8024aed9-c928-4248-b938-e15d68629ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = ['Benchmark: mean',\n",
    "          'Benchmark: median',\n",
    "          'Linear Regression',\n",
    "          'Lasso Regression',\n",
    "          'Ridge Regression',\n",
    "          'Elastic Net Regression',\n",
    "          'Random Forest Regression']\n",
    "\n",
    "modelspred = [\"mean\",\n",
    "              \"median\",\n",
    "              \"lr\",\n",
    "              \"lasso\",\n",
    "              \"ridge\",\n",
    "              \"en\",\n",
    "              \"rf\"]\n",
    "\n",
    "varname = \"manual_grouping_name\"\n",
    "\n",
    "# La matrix Y incluye todas las dependientes a predecir: el valor en cada cluster\n",
    "Y = f2c[clusters[varname]]\n",
    "\n",
    "\n",
    "# Entrenamos\n",
    "train_metrics = pd.DataFrame()\n",
    "test_metrics = pd.DataFrame()\n",
    "all_hyperparameters = {}\n",
    "\n",
    "# entrenamos un modelo para cada clúster como variable dependiente\n",
    "for c in tqdm(range(len(clusters[varname]))):\n",
    "\n",
    "    cname = clusters[varname][c]\n",
    "    y = Y.iloc[:,c]\n",
    "\n",
    "    seed(9)\n",
    "    predicted_train, predicted_test, hyperparameters = regression_methods(X_corrected, y) # usar matriz sin multicolinealidad\n",
    "    \n",
    "    # guardar valores predichos para cada clúster\n",
    "    predicted_train.to_pickle(datawd + f\"/clusters500/predicted_train_{c}.pkl\")\n",
    "    predicted_test.to_pickle(datawd + f\"/clusters500/predicted_test_{c}.pkl\")\n",
    "\n",
    "    # Métricas en TRAIN\n",
    "    train_m = pd.DataFrame()\n",
    "    train_m[\"Algorithms\"] = models\n",
    "    train_m[\"MSE\"] = [ mean_squared_error(predicted_train.y_train, predicted_train   [m]) for m in modelspred]\n",
    "    train_m[\"MSE_sd\"] = [ mean_squared_error(predicted_train.y_train, predicted_train[m])/np.mean(y**2) for m in modelspred]\n",
    "    train_m[\"MAE\"] = [ median_absolute_error(predicted_train.y_train, predicted_train[m]) for m in modelspred]\n",
    "    train_m[\"c\"] = cname\n",
    "\n",
    "    # Métricas en TEST\n",
    "    test_m = pd.DataFrame()\n",
    "    test_m[\"Algorithms\"] = models\n",
    "    test_m[\"MSE\"] =    [ mean_squared_error   (predicted_test.y_test, predicted_test[m]) for m in modelspred]\n",
    "    test_m[\"MSE_sd\"] = [ mean_squared_error   (predicted_test.y_test, predicted_test[m])/np.mean(y**2) for m in modelspred]\n",
    "    test_m[\"MAE\"] =    [ median_absolute_error(predicted_test.y_test, predicted_test[m]) for m in modelspred]                                     \n",
    "    test_m[\"c\"] = cname  \n",
    "\n",
    "\n",
    "    train_metrics = pd.concat([train_metrics, train_m], axis = 0)\n",
    "    test_metrics = pd.concat([test_metrics, test_m], axis = 0)\n",
    "    all_hyperparameters[cname] = hyperparameters\n",
    "\n",
    "# Guardar\n",
    "train_metrics.to_pickle(datawd + f\"/clusters500/train_metrics.pkl\")\n",
    "test_metrics.to_pickle(datawd + f\"/clusters500/test_metrics.pkl\")\n",
    "with open(datawd + f\"/clusters{k}/hyperparameters.pkl\", 'wb') as outputfile: \n",
    "    pickle.dump(all_hyperparameters, outputfile)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e2021c-37b0-4693-a943-d694cbae2d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in all_hyperparameters.items():\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86bb15dc-26f0-42d2-af27-65c618f48383",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heatmap con métricas de resultados\n",
    "train_metrics = pd.read_pickle(datawd + f\"/clusters500/train_metrics.pkl\")\n",
    "test_metrics = pd.read_pickle(datawd + f\"/clusters500/test_metrics.pkl\")\n",
    "\n",
    "plot_ticks =  ['Benchmark:\\n mean', 'Benchmark:\\n median', 'Elastic Net \\nRegression',\n",
    "       'Lasso \\nRegression', 'Linear\\n Regression', 'Random Forest\\n Regression',\n",
    "       'Ridge\\n Regression']\n",
    "\n",
    "# train\n",
    "df = train_metrics.pivot(index=\"c\", columns=\"Algorithms\", values = \"MSE_sd\")\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "df.columns = plot_ticks\n",
    "ax = sns.heatmap(df, \n",
    "                 yticklabels=df.index , \n",
    "                 annot=True ,\n",
    "                 cmap = \"gray_r\")\n",
    "ax = plt.xticks(rotation=0)\n",
    "ax = plt.xlabel('', fontsize=24)\n",
    "ax = plt.ylabel('', fontsize=24)\n",
    "\n",
    "ax = plt.title('MSE standardized - Train', fontsize=14)\n",
    "plt.savefig(datawd + f\"/clusters500/metrics_MSEsd_TRAIN.png\", dpi = 300, bbox_inches='tight')\n",
    "ax = plt.show()\n",
    "\n",
    "# test\n",
    "df = test_metrics.pivot(index=\"c\", columns=\"Algorithms\", values = \"MSE_sd\")\n",
    "df.columns = plot_ticks\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "ax = sns.heatmap(df, \n",
    "                 yticklabels=df.index , \n",
    "                 annot=True ,\n",
    "                 cmap = \"gray_r\")\n",
    "ax = plt.xticks(rotation=0)\n",
    "ax = plt.xlabel('', fontsize=24)\n",
    "ax = plt.ylabel('', fontsize=24)\n",
    "ax = plt.title('MSE standardized - Test', fontsize=14)\n",
    "plt.savefig(datawd + f\"/clusters500/metrics_MSEsd_TEST.png\", dpi = 300, bbox_inches='tight')\n",
    "ax = plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
